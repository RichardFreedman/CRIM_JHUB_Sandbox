{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577f63f",
   "metadata": {},
   "source": [
    "## How Presentation Types Works\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5c1fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_csv folder already exists.\n"
     ]
    }
   ],
   "source": [
    "import intervals\n",
    "from intervals import * \n",
    "from intervals import main_objs\n",
    "import intervals.visualizations as viz\n",
    "import pandas as pd\n",
    "import re\n",
    "import altair as alt \n",
    "from ipywidgets import interact\n",
    "from pandas.io.json import json_normalize\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import os\n",
    "import numpy\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from copy import deepcopy\n",
    "MYDIR = (\"saved_csv\")\n",
    "CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(MYDIR)\n",
    "    print(\"created folder : \", MYDIR)\n",
    "\n",
    "else:\n",
    "    print(MYDIR, \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71dba07",
   "metadata": {},
   "source": [
    "#### The following are special functions used by the classifier.  Don't change them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e63137",
   "metadata": {},
   "source": [
    "## Load one Piece Here\n",
    "\n",
    "* Note that you can load from CRIM, or put a file in the **Music_Files** folder in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fcd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading remote score...\n",
      "Successfully imported https://crimproject.org/mei/CRIM_Mass_0031_2.mei\n"
     ]
    }
   ],
   "source": [
    "# piece = importScore('Music_Files/CRIM_Mass_0031_1.mei')\n",
    "piece = importScore('https://crimproject.org/mei/CRIM_Mass_0031_2.mei')\n",
    "# piece = importScore('Music_Files/CRIM_Mass_0007_4.mei')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4ecf0",
   "metadata": {},
   "source": [
    "#### Below is Development Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_diffs = [2.0, 1.0, 2.0, 3.0, 5.0, 6.0]\n",
    "# some_list[start:stop:step]\n",
    "alt_list = offset_diffs[::2]\n",
    "alt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33447a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works with ONE list of offsets\n",
    "\n",
    "points2 = pd.DataFrame()\n",
    "split_list = [90.0, 94.0, 102.0, 106.0, 134.0, 146.0, 162.0]\n",
    "\n",
    "l = len(split_list)  \n",
    "for r in range(3, l):\n",
    "    list_combinations = list(combinations(split_list, r))\n",
    "#             combo_time_ints = []\n",
    "    for combo in list_combinations:\n",
    "        combo_time_ints = numpy.diff(combo).tolist()\n",
    "        combo_array = entry_array[entry_array.index.get_level_values(0).isin(combo)]\n",
    "        combo_voice_list = combo_array['voice'].to_list()\n",
    "        combo_patterns = combo_array['pattern']\n",
    "        unique_combo_patterns = list(set(combo_patterns))\n",
    "        tone_coordinates =  list(zip(combo, combo_voice_list))\n",
    "# tone_coordinates.ffill(inplace=True)\n",
    "        mel_ints = find_entry_int_distance(tone_coordinates, piece)\n",
    "        hidden_type = classify_by_offset(combo_time_ints)\n",
    "\n",
    "        meas_beat = det[det.index.get_level_values('Offset').isin(combo)]\n",
    "        mb2 = meas_beat.reset_index()\n",
    "        mb2['mb'] = mb2[\"Measure\"].astype(str) + \"/\" + mb2[\"Beat\"].astype(str)\n",
    "        meas_beat_list = mb2['mb'].to_list()\n",
    "\n",
    "        combo_temp = {'First_Offset': combo[0], \n",
    "            'Offsets': combo, \n",
    "            'Measures_Beats': meas_beat_list,\n",
    "            'Presentation_Type': hidden_type,\n",
    "            \"Soggetti\": unique_combo_patterns,\n",
    "            'Voices': combo_voice_list, \n",
    "            'Time_Entry_Intervals': combo_time_ints, \n",
    "            'Melodic_Entry_Intervals': mel_ints}\n",
    "\n",
    "        if 'PEN' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        if 'ID' in hidden_type:\n",
    "            points2 = points2.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "#             points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "        \n",
    "        \n",
    "# combo_time_ints\n",
    "# combo_array\n",
    "# # combo_voice_list\n",
    "# # combo_patterns\n",
    "# # unique_combo_patterns\n",
    "# # tone_coordinates\n",
    "# # mel_ints\n",
    "# # combo_temp\n",
    "points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28babf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finds hidden fugas.  \n",
    "# try to run each of the first set of results above ('points') through this tool, then append the \n",
    "# new results to the full DF, and sort again.  \n",
    "# mark each long pattern with 'has hidden pattern' boolean?  or ?\n",
    "\n",
    "sample_list = points[\"Offsets\"][4]\n",
    "\n",
    "hidden_pts = []\n",
    "n = len(sample_list)\n",
    "for item in range(3, n):\n",
    "    list_combinations = list(combinations(sample_list, item))\n",
    "    for group in list_combinations:\n",
    "        group_time_ints = numpy.diff(group).tolist()\n",
    "        hidden_type = classify_by_offset(group_time_ints)\n",
    "        if 'PEN' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        if 'ID' in hidden_type:\n",
    "            print(group)\n",
    "            print(group_time_ints)\n",
    "            print(hidden_type)\n",
    "            hidden_pts.append(group_time_ints)\n",
    "        \n",
    "\n",
    "list_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_entries_as_presentation_types(piece):\n",
    "    # Classifier with Functions\n",
    "    points = pd.DataFrame()\n",
    "    points2 = pd.DataFrame()\n",
    "    # new_offset_list = []\n",
    "    nr = piece.getNoteRest()\n",
    "    det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "    # durations and ngrams of durations\n",
    "    dur = piece.getDuration(df=nr)\n",
    "    dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "    # ngrams of melodic entries\n",
    "    # for chromatic, use:\n",
    "    # piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "    mel = piece.getMelodicEntries(n=4)\n",
    "    mels_stacked = mel.stack().to_frame()\n",
    "    mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "    # edit distance, based on side-by-side comparison of melodic ngrams\n",
    "    # gets flexed and other similar soggetti\n",
    "    dist = piece.getDistance(mel)\n",
    "    dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "    # filter distances to threshold.  <2 is good\n",
    "    filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "    filtered_dist = filtered_dist_stack.reset_index()\n",
    "    filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "    # Group the filtered distanced patterns\n",
    "    full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "    for matches in full_list_of_matches[\"match\"]:\n",
    "        related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "        entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "        offset_list = entry_array.index.to_list()\n",
    "        split_list = list(split_by_threshold(offset_list))\n",
    "        # here is the list of starting offsets of the original set of entries:  slist\n",
    "        slist = split_list[0]\n",
    "        temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "        points = points.append(temp, ignore_index=True)\n",
    "        points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "        points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "        points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "        l = len(slist)\n",
    "        if l > 2:\n",
    "            for r in range(3, l):\n",
    "    #             list_combinations = list(combinations(slist, r))\n",
    "                list_combinations = list(combinations(slist, r))\n",
    "                for slist in list_combinations:\n",
    "\n",
    "                    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "                    temp[\"Presentation_Type\"] = classify_by_offset(temp['Time_Entry_Intervals'])\n",
    "\n",
    "                    if 'PEN' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                        points2 = points2[points2['Offsets'].apply(len) > 1]\n",
    "                    if 'ID' in temp[\"Presentation_Type\"]:\n",
    "                        points2 = points2.append(combo_temp, ignore_index=True)#.sort_values(\"First_Offset\")\n",
    "    #                     points = points.append(combo_temp, ignore_index=True).sort_values(\"First_Offset\")\n",
    "                points2.sort_values(\"First_Offset\")\n",
    "                points2.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "\n",
    "    points_combined = points.append(points2, ignore_index=True).sort_values(\"First_Offset\").reset_index(drop=True)\n",
    "    points_combined['Flexed_Entries'] = points_combined[\"Soggetti\"].apply(len) > 1\n",
    "    points_combined[\"Number_Entries\"] = points[\"Offsets\"].apply(len)     \n",
    "    return points2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58c6bcee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only list-like objects are allowed to be passed to isin(), you passed a [float]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m         hidden_type \u001b[38;5;241m=\u001b[39m classify_by_offset(group_time_ints)\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m group:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#         print(item)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m             array \u001b[38;5;241m=\u001b[39m group[\u001b[43mentry_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     59\u001b[0m             short_offset_list \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m     60\u001b[0m             time_ints \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdiff(array\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intervals/lib/python3.9/site-packages/pandas/core/indexes/base.py:5224\u001b[0m, in \u001b[0;36mIndex.isin\u001b[0;34m(self, values, level)\u001b[0m\n\u001b[1;32m   5222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_index_level(level)\n\u001b[0;32m-> 5224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/intervals/lib/python3.9/site-packages/pandas/core/algorithms.py:435\u001b[0m, in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly list-like objects are allowed to be passed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto isin(), you passed a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(comps)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m     )\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(values):\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly list-like objects are allowed to be passed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto isin(), you passed a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    441\u001b[0m     values, (ABCIndexClass, ABCSeries, ABCExtensionArray, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    442\u001b[0m ):\n\u001b[1;32m    443\u001b[0m     values \u001b[38;5;241m=\u001b[39m _ensure_arraylike(\u001b[38;5;28mlist\u001b[39m(values))\n",
      "\u001b[0;31mTypeError\u001b[0m: only list-like objects are allowed to be passed to isin(), you passed a [float]"
     ]
    }
   ],
   "source": [
    "# This test works\n",
    "\n",
    "points = pd.DataFrame()\n",
    "points2 = pd.DataFrame()\n",
    "# new_offset_list = []\n",
    "nr = piece.getNoteRest()\n",
    "det = piece.detailIndex(nr, offset=True)\n",
    "\n",
    "# durations and ngrams of durations\n",
    "dur = piece.getDuration(df=nr)\n",
    "dur_ng = piece.getNgrams(df=dur, n=4)\n",
    "\n",
    "# ngrams of melodic entries\n",
    "# for chromatic, use:\n",
    "# piece.getMelodicEntries(interval_settings=('c', True, True), n=5)\n",
    "mel = piece.getMelodicEntries(n=4)\n",
    "mels_stacked = mel.stack().to_frame()\n",
    "mels_stacked.rename(columns =  {0:\"pattern\"}, inplace = True)\n",
    "\n",
    "# edit distance, based on side-by-side comparison of melodic ngrams\n",
    "# gets flexed and other similar soggetti\n",
    "dist = piece.getDistance(mel)\n",
    "dist_stack = dist.stack().to_frame()\n",
    "\n",
    "\n",
    "# filter distances to threshold.  <2 is good\n",
    "filtered_dist_stack = dist_stack[dist_stack[0] < 2]\n",
    "filtered_dist = filtered_dist_stack.reset_index()\n",
    "filtered_dist.rename(columns =  {'level_0':\"source\", 'level_1':'match'}, inplace = True)\n",
    "\n",
    "# Group the filtered distanced patterns\n",
    "full_list_of_matches = filtered_dist.groupby('source')['match'].apply(list).reset_index()\n",
    "\n",
    "for matches in full_list_of_matches[\"match\"]:\n",
    "    related_entry_list = mels_stacked[mels_stacked['pattern'].isin(matches)]\n",
    "    entry_array = related_entry_list.reset_index(level=1).rename(columns = {'level_1': \"voice\", 0: \"pattern\"})\n",
    "    offset_list = entry_array.index.to_list()\n",
    "    split_list = list(split_by_threshold(offset_list))\n",
    "    # here is the list of starting offsets of the original set of entries:  slist\n",
    "    slist = split_list[0]\n",
    "    temp = temp_dict_of_details(slist, entry_array, det, matches)\n",
    "\n",
    "    points = points.append(temp, ignore_index=True)\n",
    "    points['Presentation_Type'] = points['Time_Entry_Intervals'].apply(classify_by_offset)\n",
    "    points.drop_duplicates(subset=[\"First_Offset\"], keep='first', inplace = True)\n",
    "    points = points[points['Offsets'].apply(len) > 1]\n",
    "\n",
    "    test = [278.0, 286.0, 294.0, 298.0, 306.0, 310.0]\n",
    "\n",
    "    l = len(test)  \n",
    "    for item in range(3, l):\n",
    "        list_combinations = list(combinations(test, item))\n",
    "        for group in list_combinations:\n",
    "            group_time_ints = numpy.diff(group).tolist()\n",
    "            hidden_type = classify_by_offset(group_time_ints)\n",
    "            for item in group:\n",
    "    #         print(item)\n",
    "                array = group[entry_array.index.get_level_values(0).isin(item)]\n",
    "                short_offset_list = array.index.to_list()\n",
    "                time_ints = numpy.diff(array.index).tolist()\n",
    "                voice_list = array['voice'].to_list()\n",
    "                if 'PEN' in hidden_type:\n",
    "                    print(group)\n",
    "                    print(group_time_ints)\n",
    "                    print(hidden_type)\n",
    "                    hidden_pts.append(group_time_ints)\n",
    "                if 'ID' in hidden_type:\n",
    "                    print(group)\n",
    "                    print(group_time_ints)\n",
    "                    print(hidden_type)\n",
    "                    hidden_pts.append(group_time_ints)\n",
    "# len(split_list[0])           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This shows how the classifier works:\n",
    "\n",
    "if len(set(offset_diffs)) == 1 and len(offset_diffs) > 1:\n",
    "    print('This is a PEN')\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "elif (len(offset_diffs) % 2 != 0) and (len(set(alt_list)) == 1) and (len(offset_diffs) >= 3):\n",
    "    print('This is an ID')\n",
    "elif len(offset_diffs) >= 1:\n",
    "    print('This is a FUGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac85a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows how combinations works for a given set of time intervals\n",
    "offset_diffs = [12.0, 32.0, 12.0, 4.0]\n",
    "l = len(offset_diffs)\n",
    "# print(l)\n",
    "if l > 2:\n",
    "    for r in range(3, l):\n",
    "        print(r)\n",
    "        list_combinations = list(combinations(offset_diffs, r))\n",
    "#         for slist in list_combinations:\n",
    "        print(list_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82ed6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "slist = [278.0, 286.0, 294.0, 298.0, 306.0, 310.0]\n",
    "l = len(slist)\n",
    "# for r in range(3, 6):\n",
    "list_combinations = list(combinations(slist, 4))\n",
    "#     for tiny_list in list_combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0276a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(278.0, 286.0, 294.0, 298.0), (278.0, 286.0, 294.0, 306.0), (278.0, 286.0, 294.0, 310.0), (278.0, 286.0, 298.0, 306.0), (278.0, 286.0, 298.0, 310.0), (278.0, 286.0, 306.0, 310.0), (278.0, 294.0, 298.0, 306.0), (278.0, 294.0, 298.0, 310.0), (278.0, 294.0, 306.0, 310.0), (278.0, 298.0, 306.0, 310.0), (286.0, 294.0, 298.0, 306.0), (286.0, 294.0, 298.0, 310.0), (286.0, 294.0, 306.0, 310.0), (286.0, 298.0, 306.0, 310.0), (294.0, 298.0, 306.0, 310.0)]\n"
     ]
    }
   ],
   "source": [
    "print(list_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b92435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_offsets = [294.0, 298.0, 306.0, 310.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ab3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_diffs = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63932bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a FUGA\n"
     ]
    }
   ],
   "source": [
    "alt_list = offset_diffs[::2]\n",
    "\n",
    "if len(set(offset_diffs)) == 1 and len(offset_diffs) > 1:\n",
    "    print('This is a PEN')\n",
    "    # elif (len(offset_difference_list) %2 != 0) and (len(set(alt_list)) == 1):\n",
    "elif (len(offset_diffs) % 2 != 0) and (len(set(alt_list)) == 1) and (len(offset_diffs) >= 3):\n",
    "    print('This is an ID')\n",
    "elif len(offset_diffs) >= 1:\n",
    "    print('This is a FUGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d7ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
